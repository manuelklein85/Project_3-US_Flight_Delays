{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This Jupyter Notebook was created by Manuel Klein and belongs to the final project of the Data Science Bootcamp from neuefische Hamburg.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Flight Delay Analysis and Prediction\n",
    "## Part 1: Data Understanding and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first of x Jupyter Notebooks dealing with US flight delays. It covers the understanding of the data, several optimizations and an in-depth analysis and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[1. Introduction](#anchor_11)</b>\n",
    "> [1.1 Task](#anchor_11)<br>\n",
    "> [1.2 Dataset Information](#anchor_12)<br>\n",
    "\n",
    "\n",
    "<b>[2. Initial Steps](#anchor_21)</b>\n",
    "> [2.1 Adjusting Jupyter Notebook Settings](#anchor_21)<br>\n",
    "> [2.2 Importing necessary libraries](#anchor_22)<br>\n",
    "> [2.3 Importing the data](#anchor_23)\n",
    "\n",
    "<b>[3. Understanding and optimizing the features](#anchor_31)</b>\n",
    "> [3.1 Merge check](#anchor_31)<br>\n",
    "> [3.2 Basic understanding](#anchor_32)<br>\n",
    "> [3.3 Feature renaming and rearrangement](#anchor_33)<br>\n",
    "> [3.4 Adding airline names](#anchor_34)<br>\n",
    "> [3.5 Revision summary](#anchor_35)\n",
    "\n",
    "<b>[4. Adding airport data](#anchor_41)</b>\n",
    "> [4.1 Basic data understanding](#anchor_41)<br>\n",
    "> [4.2 Airport coverage check](#anchor_42)<br>\n",
    "> [4.3 Removing unnecessary features](#anchor_43)<br>\n",
    "> [4.4 Missing data overview](#anchor_44)<br>\n",
    "> [4.5 Adding airport data to original data](#anchor_45)<br>\n",
    "> [4.6 Missing data relevance check](#anchor_46)<br>\n",
    "> [4.7 Revision summary](#anchor_47)\n",
    "\n",
    "<b>[5. Detailed data check and cleanup](#anchor_5)</b>\n",
    "> [5.1 Removing cancelled and diverted flights](#anchor_51)<br>\n",
    "> [5.2 Analyzing and reducing missing values](#anchor_52)<br>\n",
    "> [5.3 Plausibility check](#anchor_53)<br>\n",
    "> [5.4 Removing non-plausible data](#anchor_54)<br>\n",
    "> [5.5 Converting flight date format](#anchor_55)<br>\n",
    "> [5.6 Adding day of week feature](#anchor_56)<br>\n",
    "> [5.7 Final data check and feature summary](#anchor_57)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_11'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims at analyzing airline delays and identifying the main influencing factors for aircraft delays. Moreover, a predictive model shall give the opportunity to estimate the likelyhood for a delay of a specific future flight. The following business cases are addressed:\n",
    "\n",
    "* Airlines need to have a deep understanding of delays for scheduling flights, planning reserve planes at specific airports etc. This includes reasons for delays as well as expected delay times.\n",
    "* Airlines want to reduce their delays. Thus they need to understand what are the main influencing factors for delays and which of them can be tackled\n",
    "* Airlines want to understand if the perform better or worse in comparison to their competitors regarding delay at e.g. a specific flight route\n",
    "* Passengers want to know how likely a certain delay for a specific booking is (e.g. departure and landing airports, date, day of the week, time etc.) and how high that delay might be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_12'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was taken from the following website (downloaded on 12/09/2019):<br>\n",
    "https://www.kaggle.com/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018\n",
    "\n",
    "The data originally comes from the United States Department of Transportation:<br>\n",
    "https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time\n",
    "\n",
    "Airport information data was taken from the following website (downloaded on 12/10/2019):<br>\n",
    "https://openflights.org/data.html<br>\n",
    "Necessary data about airports not included in the data file from this website was added manually with information from various internet sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_21'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Adjusting Jupyter Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusting the Jupyter Notebook window width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown tables left alignment and markdown table cell content left aligment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "table {float:left}\n",
       "table td, table th, table tr {text-align:left !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> \n",
    "table {float:left}\n",
    "table td, table th, table tr {text-align:left !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_22'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import datetime\n",
    "import missingno as msno\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pandas display options to have more columns shown in .head() etc.\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_23'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The needed data is imported for each year separately for separate analysis and computation. All data is also stored in a single dataframe for overall analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data for 2016\n",
    "df16 = pd.read_csv(r'C:\\Project_Data_NF/2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data for 2017\n",
    "df17 = pd.read_csv(r'C:\\Project_Data_NF/2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data for 2018\n",
    "df18 = pd.read_csv(r'C:\\Project_Data_NF/2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data into one dataframe\n",
    "df = pd.concat([df16, df17, df18], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(r'C:\\Project_Data_NF/airports_worldwide.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Merge check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the number of observations in df is the sum of observations in df16, df17 and df18\n",
    "len(df16)+len(df17)+len(df18) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking if all .csv-Files contain the same features and the same feature format\n",
    "print(df16.info())\n",
    "print(df17.info())\n",
    "print(df18.info())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`➜ All .csv-Files contain the same features and feature formats.`**<br>\n",
    "**`➜ Merging the dataframes was successful. In the following only the merged dataset will be used as data for single years can easily be filtered from it.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing RAM load by removing no longer needed data\n",
    "df16 = df17 = df18 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Basic understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature description from the dataset website:**\n",
    "\n",
    "| Feature No. | Feature Name | Description |\n",
    "| :-: | :-: | :-: |\n",
    "| 1 | FL_DATE | Date of the flight, yy/mm/dd |\n",
    "| 2 | OP_CARRIER | Airline Identifier |\n",
    "| 3 | OP_CARRIER_FL_NUM | Flight Number |\n",
    "| 4 | ORIGIN | Starting Airport IATA-Code |\n",
    "| 5 | DEST | Destination Airport IATA-Code |\n",
    "| 6 | CRS_DEP_TIME | Planned Departure Time |\n",
    "| 7 | DEP_TIME | Actual Departure Time |\n",
    "| 8 | DEP_DELAY | Total Delay on Departure in minutes |\n",
    "| 9 | TAXI_OUT | The time duration elapsed between departure from the origin airport gate and wheels off |\n",
    "| 10 | WHEELS_OFF | The time point that the aircraft's wheels leave the ground |\n",
    "| 11 | WHEELS_ON | The time point that the aircraft's wheels touch on the ground |\n",
    "| 12 | TAXI_IN | The time duration elapsed between wheels-on and gate arrival at the destination airport |\n",
    "| 13 | CRS_ARR_TIME | Planned arrival time |\n",
    "| 14 | ARR_TIME | Actual Arrival Time |\n",
    "| 15 | ARR_DELAY | Total Delay on Arrival in minutes |\n",
    "| 16 | CANCELLED | Flight Cancelled (0 = not cancelled, 1 = cancelled) |\n",
    "| 17 | CANCELLATION_CODE | Reason for Cancellation of flight: A - Airline/Carrier; B - Weather; C - National Air System; D - Security |\n",
    "| 18 | DIVERTED | Aircraft landed on airport that out of schedule |\n",
    "| 19 | CRS_ELAPSED_TIME | Planned time amount needed for the flight trip |\n",
    "| 20 | ACTUAL_ELAPSED_TIME | AIR_TIME+TAXI_IN+TAXI_OUT |\n",
    "| 21 | AIR_TIME | The time duration between wheels_off and wheels_on time |\n",
    "| 22 | DISTANCE | Distance between two airports |\n",
    "| 23 | CARRIER_DELAY | Delay caused by the airline in minutes |\n",
    "| 24 | WEATHER_DELAY | Delay caused by weather |\n",
    "| 25 | NAS_DELAY | Delay caused by air system |\n",
    "| 26 | SECURITY_DELAY | Delay caused by security |\n",
    "| 27 | LATE_AIRCRAFT_DELAY | Delay caused by aircraft |\n",
    "| 28 | Unnamed: 27 | Useless column |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding aircraft delays:**<br><br>\n",
    "Source: https://www.bts.gov/topics/airlines-and-airports/understanding-reporting-causes-flight-delays-and-cancellations\n",
    "\n",
    "| Delay Reason | Description |\n",
    "| :-: | :-: |\n",
    "| Air Carrier | The cause of the cancellation or delay was due to circumstances within the airline's control (e.g. maintenance or crew problems, aircraft cleaning, baggage loading, fueling, etc.). |\n",
    "| Extreme Weather | Significant meteorological conditions (actual or forecasted) that, in the judgment of the carrier, delays or prevents the operation of a flight such as tornado, blizzard or hurricane. |\n",
    "| National Aviation System (NAS) | Delays and cancellations attributable to the national aviation system that refer to a broad set of conditions, such as non-extreme weather conditions, airport operations, heavy traffic volume, and air traffic control. |\n",
    "| Late-arriving aircraft | A previous flight with same aircraft arrived late, causing the present flight to depart late. |\n",
    "| Security | Delays or cancellations caused by evacuation of a terminal or concourse, re-boarding of aircraft because of security breach, inoperative screening equipment and/or long lines in excess of 29 minutes at screening areas. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First impression of the data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the last column ('Unnamed: 27') in the Dataset as it is a useless column according to the feature description\n",
    "df = df.iloc[:,:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feature renaming and rearrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns to make them easier understandable\n",
    "column_renaming_dict = {\"OP_CARRIER\": \"AIRLINE_ID\",\n",
    "                        \"OP_CARRIER_FL_NUM\": \"FL_NUMBER\",\n",
    "                        \"ORIGIN\": \"DEP_AIRPORT\",\n",
    "                        \"DEST\": \"ARR_AIRPORT\",\n",
    "                        \"CRS_DEP_TIME\": \"DEP_TIME_PLANNED\",\n",
    "                        \"TAXI_OUT\": \"TAXI_OUT_DURATION\",\n",
    "                        \"WHEELS_OFF\": \"WHEELS_OFF_TIME\",\n",
    "                        \"WHEELS_ON\": \"WHEELS_ON_TIME\",\n",
    "                        \"TAXI_IN\": \"TAXI_IN_DURATION\",\n",
    "                        \"CRS_ARR_TIME\": \"ARR_TIME_PLANNED\",\n",
    "                        \"CRS_ELAPSED_TIME\": \"TRAVEL_DURATION_PLANNED\",\n",
    "                        \"ACTUAL_ELAPSED_TIME\": \"TRAVEL_DURATION\",\n",
    "                        \"AIR_TIME\": \"IN_AIR_DURATION\"}\n",
    "\n",
    "df.rename(columns=column_renaming_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the order of features in the dataframes for better overview\n",
    "optimized_column_order = [\"FL_DATE\", \"AIRLINE_ID\", \"FL_NUMBER\", \"DEP_AIRPORT\", \"ARR_AIRPORT\", \"DISTANCE\", \"DEP_TIME_PLANNED\",\n",
    "                          \"DEP_TIME\", \"DEP_DELAY\", \"TAXI_OUT_DURATION\", \"WHEELS_OFF_TIME\", \"WHEELS_ON_TIME\", \"IN_AIR_DURATION\", \"TAXI_IN_DURATION\",\n",
    "                          \"ARR_TIME_PLANNED\", \"ARR_TIME\", \"ARR_DELAY\", \"TRAVEL_DURATION_PLANNED\", \"TRAVEL_DURATION\", \"DIVERTED\", \"CANCELLED\",\n",
    "                          \"CANCELLATION_CODE\", \"CARRIER_DELAY\", \"WEATHER_DELAY\", \"NAS_DELAY\", \"SECURITY_DELAY\", \"LATE_AIRCRAFT_DELAY\"]\n",
    "\n",
    "df = df.reindex(columns=optimized_column_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Adding airline names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking which airline IDs are included in the dataset\n",
    "sorted(df[\"AIRLINE_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Understanding the meaning of the airline IDs (IATA codes)\n",
    "# Data source: https://en.wikipedia.org/wiki/List_of_airline_codes\n",
    "airline_dict = {'9E': 'Endeavor Air',\n",
    "                'AA': 'American Airlines',\n",
    "                'AS': 'Alaska Airlines',\n",
    "                'B6': 'JetBlue Airways',\n",
    "                'DL': 'Delta Air Lines',\n",
    "                'EV': 'ExpressJet Airlines LLC',\n",
    "                'F9': 'Frontier Airlines',\n",
    "                'G4': 'Allegiant Air',\n",
    "                'HA': 'Hawaiian Airlines',\n",
    "                'MQ': 'Envoy Air',\n",
    "                'NK': 'Spirit Airlines,',\n",
    "                'OH': 'PSA Airlines',\n",
    "                'OO': 'SkyWest Airlines',\n",
    "                'UA': 'United Air Lines',\n",
    "                'VX': 'Virgin America',\n",
    "                'WN': 'Southwest Airlines Co.',\n",
    "                'YV': 'Mesa Airlines',\n",
    "                'YX': 'Midwest Airlines'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column with airline names\n",
    "df['AIRLINE_NAME'] = df['AIRLINE_ID'].values\n",
    "df['AIRLINE_NAME'] = df['AIRLINE_NAME'].map(airline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the index of the newly created column\n",
    "df.columns.get_loc(\"AIRLINE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the new created airline name column next to the airline ID column\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[0:2] + [cols[27]] + cols[2:27]\n",
    "df = df.reindex(columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Revision summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if all steps described above were successfully performed\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature explanation after revision:**\n",
    "\n",
    "Features containing time information refer to actual time except their name contains the key word \"planned\".<br>\n",
    "Features containing the keyword \"time\" always describe a point in time. Otherwise the word \"duration\" is used.\n",
    "\n",
    "\n",
    "|Feature No. | Feature Name | Description |\n",
    "| :-: | :-: | :-: |\n",
    "| 1 | FL_DATE | Date of the flight, yy/mm/dd |\n",
    "| 2 | AIRLINE_ID | Airline Identifier |\n",
    "| 3 | AIRLINE_NAME | Name of the airline |\n",
    "| 4 | FL_NUMBER | Flight Number |\n",
    "| 5 | DEP_AIRPORT | Departure Airport IATA-Code |\n",
    "| 6 | ARR_AIRPORT | Arrival Airport IATA-Code |\n",
    "| 7 | DISTANCE | Distance between departure airport and arrival airport in miles |\n",
    "| 8 | DEP_TIME_PLANNED | Planned Departure Time |\n",
    "| 9 | DEP_TIME | Actual Departure Time |\n",
    "| 10 | DEP_DELAY | Total Delay on Departure in minutes |\n",
    "| 11 | TAXI_OUT_DURATION | The time duration elapsed between departure from the departure airport gate and wheels off |\n",
    "| 12 | WHEELS_OFF_TIME | The time point that the aircraft's wheels leave the ground |\n",
    "| 13 | WHEELS_ON_TIME | The time point that the aircraft's wheels touch on the ground |\n",
    "| 14 | IN_AIR_DURATION | The time duration between wheels_off and wheels_on time |\n",
    "| 15 | TAXI_IN_DURATION | The time duration elapsed between wheels-on and gate arrival at the arrival airport |\n",
    "| 16 | ARR_TIME_PLANNED | Planned arrival time |\n",
    "| 17 | ARR_TIME | Actual arrival Time |\n",
    "| 18 | ARR_DELAY | Total delay on arrival in minutes |\n",
    "| 19 | TRAVEL_DURATION_PLANNED | Planned time amount needed for the flight trip |\n",
    "| 20 | TRAVEL_DURATION | Actual time amount needed for the flight trip |\n",
    "| 21 | DIVERTED | Aircraft landed on a different airport than planned (0 = no, 1 = yes) |\n",
    "| 22 | CANCELLED | Flight Cancelled (0 = not cancelled, 1 = cancelled) |\n",
    "| 23 | CANCELLATION_CODE | Reason for Cancellation of flight: A - Airline/Carrier; B - Weather; C - National Air System; D - Security |\n",
    "| 24 | CARRIER_DELAY | Delay caused by the airline in minutes |\n",
    "| 25 | WEATHER_DELAY | Delay caused by weather |\n",
    "| 26 | NAS_DELAY | Delay caused by air system |\n",
    "| 27 | SECURITY_DELAY | Delay caused by security |\n",
    "| 28 | LATE_AIRCRAFT_DELAY | Delay caused by aircraft |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_41'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding airport data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Basic data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking the number of US airports for each time zone. '\\N' means 'NaN'\n",
    "airports[airports['Country'] == \"United States\"]['Timezone'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Offset | Timezone | Abbreviation | Name | Example City |\n",
    "| :-: | :-: | :-: | :-: | :-: |\n",
    "| UTC | -10 | HST | Hawaii Standard Time | Honolulu |\n",
    "| UTC | -9 | AKST | Alaska Standard Time | Anchorage |\n",
    "| UTC | -8 | PST | Pacific Standard Time | Los Angeles |\n",
    "| UTC | -7 | MST | Mountain Standard Time | Salt Lake City |\n",
    "| UTC | -6 | CST | Central Standard Time | Chicago |\n",
    "| UTC | -5 | ES | Eastern Standard Time | New York |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_42'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Airport coverage check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = df[\"DEP_AIRPORT\"].unique()\n",
    "a2 = df[\"ARR_AIRPORT\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = airports[\"IATA\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if all airports mentioned in the flights dataset are included in the airport dataset\n",
    "# Return the unique values in a that are not in b\n",
    "print(np.setdiff1d(a1, b))\n",
    "print(np.setdiff1d(a2, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`➜ All airports mentioned in the flights dataset are included in the airport dataset.`**<br>\n",
    "**`➜ However, filtering the country for \"United States\" in advance leads to airport information missing.`**<br>\n",
    "**`This means that some airports of the flight dataset are outside the United States!`**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_43'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Removing unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting columns that are not needed for this project\n",
    "airports.drop(columns=['Airport_ID','Country','Type','Source', 'ICAO','DST'], inplace=True)\n",
    "#airports.drop(columns=['Airport_ID','Country','ICAO','Timezone','DST','Tz_database_time_zone','Type','Source'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset after deletion of unnecessary columns\n",
    "airports.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_44'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Missing data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing '\\N' entries in the dataset by NaN values, enabling missing data analysis\n",
    "airports = airports.replace(r'\\N', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the number of NaN values for each feature inside the airport dataset\n",
    "airports.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the percentage of NaN values for each feature inside the airport dataset\n",
    "airports.isna().sum() / len(airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_45'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Adding airport data to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing departure airport data for merging\n",
    "dep_airports = airports.copy()\n",
    "dep_airports = dep_airports.rename(columns={\"Name\": \"DEP_AIRPORT_NAME\",\n",
    "                                            \"City\": \"DEP_CITY\",\n",
    "                                            \"IATA\": \"DEP_AIRPORT\",\n",
    "                                            \"Latitude\":\"DEP_LAT\",\n",
    "                                            \"Longitude\": \"DEP_LONG\",\n",
    "                                            \"Altitude\": \"DEP_ALT\",\n",
    "                                            \"Timezone\": \"DEP_UTC\",\n",
    "                                            \"Tz_database_time_zone\": \"DEP_TZ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing arrival airport data for merging\n",
    "arr_airports = airports.copy()\n",
    "arr_airports = arr_airports.rename(columns={\"Name\": \"ARR_AIRPORT_NAME\",\n",
    "                                            \"City\": \"ARR_CITY\",\n",
    "                                            \"IATA\": \"ARR_AIRPORT\",\n",
    "                                            \"Latitude\":\"ARR_LAT\",\n",
    "                                            \"Longitude\": \"ARR_LONG\",\n",
    "                                            \"Altitude\": \"ARR_ALT\",\n",
    "                                            \"Timezone\": \"ARR_UTC\",\n",
    "                                            \"Tz_database_time_zone\": \"ARR_TZ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_airports.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_airports.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging departure airport data to original dataframe\n",
    "df = pd.merge(df, dep_airports, on='DEP_AIRPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging arrival airport data to original dataframe\n",
    "df = pd.merge(df, arr_airports, on='ARR_AIRPORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_46'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Missing data relevance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe containing all features that have been added to the original dataframe\n",
    "df_new = df[['DEP_AIRPORT_NAME', 'DEP_CITY','DEP_LAT','DEP_LONG','DEP_ALT', 'DEP_UTC', 'DEP_TZ', 'ARR_AIRPORT_NAME', 'ARR_CITY','ARR_LAT','ARR_LONG','ARR_ALT', 'ARR_UTC', 'ARR_TZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if any of the NaN values from the airport dataset are relevant for the flights dataset\n",
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`➜ Luckily no NaN values from the airport dataset are relevant for the flights dataset at hand.`**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing RAM load by removing no longer needed data\n",
    "df_new = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_47'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Revision summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature explanation after including airport data:**\n",
    "\n",
    "Features containing time information refer to actual time except their name contains the key word \"planned\".<br>\n",
    "Features containing the keyword \"time\" always describe a point in time. Otherwise the word \"duration\" is used.\n",
    "\n",
    "\n",
    "|Feature No. | Feature Name | Description |\n",
    "| :-: | :-: | :-: |\n",
    "| 1 | FL_DATE | Date of the flight, yyyy-mm-dd |\n",
    "| 2 | AIRLINE_ID | Airline Identifier |\n",
    "| 3 | AIRLINE_NAME | Name of the airline |\n",
    "| 4 | FL_NUMBER | Flight Number |\n",
    "| 5 | DEP_AIRPORT | Departure Airport IATA-Code |\n",
    "| 6 | ARR_AIRPORT | Arrival Airport IATA-Code |\n",
    "| 7 | DISTANCE | Distance between departure airport and arrival airport in miles |\n",
    "| 8 | DEP_TIME_PLANNED | Planned Departure Time |\n",
    "| 9 | DEP_TIME | Actual Departure Time |\n",
    "| 10 | DEP_DELAY | Total Delay on Departure in minutes |\n",
    "| 11 | TAXI_OUT_DURATION | The time duration elapsed between departure from the departure airport gate and wheels off in minutes|\n",
    "| 12 | WHEELS_OFF_TIME | The time point that the aircraft's wheels leave the ground |\n",
    "| 13 | WHEELS_ON_TIME | The time point that the aircraft's wheels touch on the ground |\n",
    "| 14 | IN_AIR_DURATION | The time duration between wheels_off and wheels_on time in minutes |\n",
    "| 15 | TAXI_IN_DURATION | The time duration elapsed between wheels-on and gate arrival at the arrival airport in minutes |\n",
    "| 16 | ARR_TIME_PLANNED | Planned arrival time |\n",
    "| 17 | ARR_TIME | Actual arrival Time |\n",
    "| 18 | ARR_DELAY | Total delay on arrival in minutes |\n",
    "| 19 | TRAVEL_DURATION_PLANNED | Planned time amount needed for the flight trip in minutes |\n",
    "| 20 | TRAVEL_DURATION | Actual time amount needed for the flight trip in minutes |\n",
    "| 21 | DIVERTED | Aircraft landed on a different airport than planned (0 = no, 1 = yes) |\n",
    "| 22 | CANCELLED | Flight Cancelled (0 = not cancelled, 1 = cancelled) |\n",
    "| 23 | CANCELLATION_CODE | Reason for Cancellation of flight: A - Airline/Carrier; B - Weather; C - National Air System; D - Security |\n",
    "| 24 | CARRIER_DELAY | Delay caused by the airline in minutes |\n",
    "| 25 | WEATHER_DELAY | Delay caused by weather in minutes |\n",
    "| 26 | NAS_DELAY | Delay caused by air system in minutes |\n",
    "| 27 | SECURITY_DELAY | Delay caused by security in minutes |\n",
    "| 28 | LATE_AIRCRAFT_DELAY | Delay caused by aircraft in minutes|\n",
    "| 29 | DEP_AIRPORT_NAME | Name of departure airport |\n",
    "| 30 | DEP_CITY | Name of departure city |\n",
    "| 31 | DEP_LAT | Latitude of departure airport |\n",
    "| 32 | DEP_LONG | Longitude of departure airport |\n",
    "| 33 | DEP_ALT | Altitude of departure airport in ft |\n",
    "| 34 | DEP_UTC | UTC time of departure airport |\n",
    "| 35 | DEP_TZ | TZ Olson time of departure airport |\n",
    "| 36 | ARR_AIRPORT_NAME | Name of arrival airport |\n",
    "| 37 | ARR_CITY | Name of arrival city |\n",
    "| 38 | ARR_LAT | Latitude of arrival airport |\n",
    "| 39 | ARR_LONG | Longitude of arrival airport |\n",
    "| 40 | ARR_ALT | Altitude of arrival airport in ft |\n",
    "| 41 | ARR_UTC | UTC time of arrival airport |\n",
    "| 42 | ARR_TZ | TZ Olson time of arrival airport |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(r'C:\\Project_Data_NF\\dfendofstep4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_51'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed data check and cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* Times into time format?\n",
    "* Adding holiday column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'C:\\Project_Data_NF/dfendofstep4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Overview of current dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_51'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Removing cancelled and diverted flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diverted flights contain many values that are not interpretable. The arrival time e.g. is not interpretable as the information to which airport a diverted flight actually went is missing. Keeping this data would even tend to falsify analyses and thus is removed from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancelled flights contain many NaN values and do not help to predict flight delay. Thus these flights are removed as well. A data analysis for cancelled flights can still be perfomed with the pickled data status at the end of chapter 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0.2 percent of all flights have been diverted\n",
    "df['DIVERTED'].value_counts().values[1] / df['DIVERTED'].value_counts().values[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.45 percent of all flights have been cancelled\n",
    "df['CANCELLED'].value_counts().values[1] / df['CANCELLED'].value_counts().values[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.67 percent of data is lost by removing all flights from the dataset that are diverted or cancelled\n",
    "(1 - (len(df[((df['DIVERTED'] == 0) & (df['CANCELLED'] == 0))])) / len(df)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing diverted and cancelled flights from the dataset\n",
    "df = df[((df['DIVERTED'] == 0) & (df['CANCELLED'] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index, so that the last ID is equal to the number of rows in the dataset\n",
    "# Necessary after rows have been dropped, so that access via index (e.g. .iloc) works correctly\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns related to diverted and cancelled flights as the do no longer contain any information\n",
    "df.drop(columns=['DIVERTED','CANCELLED', 'CANCELLATION_CODE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping all flights from and to airports with a positive UTC leads to a removal of flight over the data line\n",
    "# This step is necessary for re-calculation of features\n",
    "# Dropping all flights from and to airports with a positive UTC leads to a neglectible loss of data (0.01%)\n",
    "(1 - (len(df[((df['DEP_UTC'].astype('int') < 0) & (df['ARR_UTC'].astype('int') < 0))]) / len(df))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the dropping of all flights from and to airports with a positive UTC\n",
    "df = df[((df['DEP_UTC'].astype('int') < 0) & (df['ARR_UTC'].astype('int') < 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index, so that the last ID is equal to the number of rows in the dataset\n",
    "# Necessary after rows have been dropped, so that access via index (e.g. .iloc) works correctly\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_52'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Analyzing and reducing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the absolute and relative amount of NaN values for each feature inside the flights dataset\n",
    "s_missing = df.isna().sum()\n",
    "s_missing_percentage = df.isna().sum() / len(df) * 100\n",
    "df_missing = pd.concat([s_missing, s_missing_percentage], axis=1)\n",
    "df_missing.columns = ['Absolute missing', 'Percentage missing']\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN Values are okay for columns describing delay reasons as not all flights have delays. In this case these columns are empty.<br>\n",
    "Missing data for 'DEP_DELAY' and 'ARR_DELAY' can be recalculated as follows:\n",
    "* DEP_DELAY = DEP_TIME - DEP_TIME_PLANNED\n",
    "* ARR_DELAY = ARR_TIME - ARR_TIME_PLANNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_DELAY_NEW'] = df[df['DEP_DELAY'].isna()]['DEP_TIME'] - df[df['DEP_DELAY'].isna()]['DEP_TIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['DEP_DELAY_NEW'].notna()]['DEP_DELAY_NEW'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARR_DELAY_NEW'] = df[df['ARR_DELAY'].isna()]['ARR_TIME'] - df[df['ARR_DELAY'].isna()]['ARR_TIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ARR_DELAY_NEW'].notna()]['ARR_DELAY_NEW'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that all missing values for 'DEP_DELAY' and 'ARR_DELAY' are zero and thus can be filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the columns that were created for analysis purposes\n",
    "df.drop(columns=['DEP_DELAY_NEW','ARR_DELAY_NEW'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values for 'DEP_DELAY' and 'ARR_DELAY' are filled with zeros\n",
    "df['DEP_DELAY'].fillna(0, inplace=True)\n",
    "df['ARR_DELAY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with neglectable amount of missing data without further analysis\n",
    "df = df[df['WHEELS_ON_TIME'].notna()]\n",
    "df = df[df['IN_AIR_DURATION'].notna()]\n",
    "df = df[df['TAXI_IN_DURATION'].notna()]\n",
    "df = df[df['ARR_TIME'].notna()]\n",
    "df = df[df['TRAVEL_DURATION'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index, so that the last ID is equal to the number of rows in the dataset\n",
    "# Necessary after rows have been dropped, so that access via index (e.g. .iloc) works correctly\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if missing value cleanup was successful\n",
    "s_missing = df.isna().sum()\n",
    "s_missing_percentage = df.isna().sum() / len(df) * 100\n",
    "df_missing = pd.concat([s_missing, s_missing_percentage], axis=1)\n",
    "df_missing.columns = ['Absolute missing', 'Percentage missing']\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_53'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Plausibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().loc[['min','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings:\n",
    " * DEP_TIME, WHEELS_OFF_TIME, WHEELS_ON_TIME, ARR_TIME_PLANNED, ARR_TIME: Max value is 2400, which is not compatible with datetime format. 24:00 to be converted to 00:00.\n",
    " * DEP_DELAY: Min and max values not plausible. To be clarified.\n",
    " * TRAVEL_DURATION_PLANNED: Negative values clearly show wrong calculation\n",
    " * With help of the distance, realistic flight durations can be estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_54'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Removing non-plausible data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeconverter(x):\n",
    "    if x == 2400:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 24:00 to 00:00\n",
    "df['DEP_TIME'] = df['DEP_TIME'].apply(timeconverter)\n",
    "df['WHEELS_OFF_TIME'] = df['WHEELS_OFF_TIME'].apply(timeconverter)\n",
    "df['WHEELS_ON_TIME'] = df['WHEELS_ON_TIME'].apply(timeconverter)\n",
    "df['ARR_TIME_PLANNED'] = df['ARR_TIME_PLANNED'].apply(timeconverter)\n",
    "df['ARR_TIME'] = df['ARR_TIME'].apply(timeconverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a feature for average travel speed\n",
    "df['AVERAGE_MPH_PLANNED'] = df['DISTANCE'] / (df['TRAVEL_DURATION_PLANNED'] / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['AVERAGE_MPH_PLANNED'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 575 Mph is the expected max. flight speed. As planes are slower during takeoff and landing, even a buffer is included in this calculation.\n",
    "# 54 flights in the dataset have an average travel speed that is larger than 575 Mph\n",
    "df[df['AVERAGE_MPH_PLANNED'] > 575].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing flights in the dataset that have an average travel speed that is larger than 575 Mph or negative\n",
    "df = df[df['AVERAGE_MPH_PLANNED'] < 575]\n",
    "df = df[df['AVERAGE_MPH_PLANNED'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index, so that the last ID is equal to the number of rows in the dataset\n",
    "# Necessary after rows have been dropped, so that access via index (e.g. .iloc) works correctly\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing column as no longer needed\n",
    "df.drop(columns=['AVERAGE_MPH_PLANNED'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(r'C:\\Project_Data_NF\\dfendofstep54.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_55'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Convert features to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'DEP_TIME_PLANNED' and 'ARR_TIME_PLANNED' to datetime (several intermediate steps necessary)\n",
    "df['DISTANCE'] = df['DISTANCE'].astype('int64')\n",
    "df['DEP_TIME_PLANNED_STR'] = df['DEP_TIME_PLANNED'].astype('str')\n",
    "df['ARR_TIME_PLANNED_STR'] = df['ARR_TIME_PLANNED'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropadding(x):\n",
    "    if len(x) == 1:\n",
    "        x = '000' + x\n",
    "    elif len(x) == 2:\n",
    "        x = '00' + x\n",
    "    elif len(x) == 3:\n",
    "        x = '0' + x\n",
    "    if len(x) != 4:\n",
    "        print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_TIME_PLANNED_STR'] = df['DEP_TIME_PLANNED_STR'].apply(zeropadding)\n",
    "df['ARR_TIME_PLANNED_STR'] = df['ARR_TIME_PLANNED_STR'].apply(zeropadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloninseration(x):\n",
    "    x = str(x)\n",
    "    return x[:-2] + ':' + x[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DEP_TIME_PLANNED_STR'] = df['DEP_TIME_PLANNED_STR'].apply(coloninseration)\n",
    "df['ARR_TIME_PLANNED_STR'] = df['ARR_TIME_PLANNED_STR'].apply(coloninseration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DEP_DATETIME_PLANNED'] = df['FL_DATE'] + ' ' + df['DEP_TIME_PLANNED_STR']\n",
    "df['ARR_DATETIME_PLANNED'] = df['FL_DATE'] + ' ' + df['ARR_TIME_PLANNED_STR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strtodatetime(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_DATETIME_PLANNED'] = df['DEP_DATETIME_PLANNED'].apply(strtodatetime)\n",
    "df['ARR_DATETIME_PLANNED'] = df['ARR_DATETIME_PLANNED'].apply(strtodatetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing column as no longer needed\n",
    "df.drop(columns=['DEP_TIME_PLANNED_STR', 'ARR_TIME_PLANNED_STR'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature, delivering negative values if arrival date is departure date + 1 day\n",
    "df['OVERMIDNIGHT'] = df['ARR_TIME_PLANNED'] - df['DEP_TIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overmidnighttobinary(x):\n",
    "    if x >= 0:\n",
    "        x = 0\n",
    "    elif x < 0:\n",
    "        x = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the values of OVERMIDNIGHT to 1 if arrival date is departure date + 1 day, otherwise to 0\n",
    "df['OVERMIDNIGHT'] = df['OVERMIDNIGHT'].apply(overmidnighttobinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARR_DATETIME_PLANNED2'] = df[df['OVERMIDNIGHT'] == 1]['ARR_DATETIME_PLANNED'] + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ARR_DATETIME_PLANNED2'].isnull(),'ARR_DATETIME_PLANNED2'] = df['ARR_DATETIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ARR_DATETIME_PLANNED'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"ARR_DATETIME_PLANNED2\": \"ARR_DATETIME_PLANNED\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['OVERMIDNIGHT'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the feature 'FL_DATE' in date/time format\n",
    "df['FL_DATE'] = df['FL_DATE'].astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plausibility check: There should be no day with no flights in the USA between 2016 and 2018 --> OK\n",
    "from datetime import date, timedelta\n",
    "date_set = set(df.FL_DATE.min() + timedelta(x) for x in range((df.FL_DATE.max() - df.FL_DATE.min()).days))\n",
    "missing = sorted(date_set - set(df.FL_DATE))\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_56'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Adding day of week feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for day of week (Monday=0, Sunday=6)\n",
    "df['FL_DAYOFWEEK'] = df['FL_DATE'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving day of week column next to the FL_DATE column\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[0:1] + [cols[42]] + cols[1:42]\n",
    "df = df.reindex(columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='anchor_57'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Final data check and feature summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature explanation after data cleaning:**\n",
    "\n",
    "Features containing time information refer to actual time except their name contains the key word \"planned\".<br>\n",
    "Features containing the keyword \"time\" always describe a point in time. Otherwise the word \"duration\" is used.\n",
    "\n",
    "\n",
    "|Feature No. | Feature Name | Description |\n",
    "| :-: | :-: | :-: |\n",
    "| 1 | FL_DATE | Date of the flight, yyyy-mm-dd |\n",
    "| 2 | FL_DAYOFWEEK | Day of week of the flight (Monday=0, Sunday=6) |\n",
    "| 3 | AIRLINE_ID | Airline Identifier |\n",
    "| 4 | AIRLINE_NAME | Name of the airline |\n",
    "| 5 | FL_NUMBER | Flight Number |\n",
    "| 6 | DEP_AIRPORT | Departure Airport IATA-Code |\n",
    "| 7 | ARR_AIRPORT | Arrival Airport IATA-Code |\n",
    "| 8 | DISTANCE | Distance between departure airport and arrival airport in miles |\n",
    "| 9 | DEP_TIME_PLANNED | Planned Departure Time |\n",
    "| 10 | DEP_TIME | Actual Departure Time |\n",
    "| 11 | DEP_DELAY | Total Delay on Departure in minutes |\n",
    "| 12 | TAXI_OUT_DURATION | The time duration elapsed between departure from the departure airport gate and wheels off in minutes|\n",
    "| 13 | WHEELS_OFF_TIME | The time point that the aircraft's wheels leave the ground |\n",
    "| 14 | WHEELS_ON_TIME | The time point that the aircraft's wheels touch on the ground |\n",
    "| 15 | IN_AIR_DURATION | The time duration between wheels_off and wheels_on time in minutes |\n",
    "| 16 | TAXI_IN_DURATION | The time duration elapsed between wheels-on and gate arrival at the arrival airport in minutes |\n",
    "| 17 | ARR_TIME_PLANNED | Planned arrival time |\n",
    "| 18 | ARR_TIME | Actual arrival Time |\n",
    "| 19 | ARR_DELAY | Total delay on arrival in minutes |\n",
    "| 20 | TRAVEL_DURATION_PLANNED | Planned time amount needed for the flight trip in minutes |\n",
    "| 21 | TRAVEL_DURATION | Actual time amount needed for the flight trip in minutes |\n",
    "| 22 | CARRIER_DELAY | Delay caused by the airline in minutes |\n",
    "| 23 | WEATHER_DELAY | Delay caused by weather in minutes |\n",
    "| 24 | NAS_DELAY | Delay caused by air system in minutes |\n",
    "| 25 | SECURITY_DELAY | Delay caused by security in minutes |\n",
    "| 26 | LATE_AIRCRAFT_DELAY | Delay caused by aircraft in minutes|\n",
    "| 27 | DEP_AIRPORT_NAME | Name of departure airport |\n",
    "| 28 | DEP_CITY | Name of departure city |\n",
    "| 29 | DEP_LAT | Latitude of departure airport |\n",
    "| 30 | DEP_LONG | Longitude of departure airport |\n",
    "| 31 | DEP_ALT | Altitude of departure airport in ft |\n",
    "| 32 | DEP_UTC | UTC time of departure airport |\n",
    "| 33 | DEP_TZ | TZ Olson time of departure airport |\n",
    "| 34 | ARR_AIRPORT_NAME | Name of arrival airport |\n",
    "| 35 | ARR_CITY | Name of arrival city |\n",
    "| 36 | ARR_LAT | Latitude of arrival airport |\n",
    "| 37 | ARR_LONG | Longitude of arrival airport |\n",
    "| 38 | ARR_ALT | Altitude of arrival airport in ft |\n",
    "| 39 | ARR_UTC | UTC time of arrival airport |\n",
    "| 40 | ARR_TZ | TZ Olson time of arrival airport |\n",
    "| 41 | DEP_DATETIME_PLANNED | UTC time of arrival airport |\n",
    "| 42 | OVERMIDNIGHT | 1 if flight is over midnight, 0 if not |\n",
    "| 43 | ARR_DATETIME_PLANNED | TZ Olson time of arrival airport |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(r'C:\\Project_Data_NF\\dfendofstep5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No longer needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tackling identified issues**:\n",
    "\n",
    "Estimating trustworthy features:\n",
    "* DEP_TIME_PLANNED\n",
    "* ARR_TIME_PLANNED\n",
    "* DEP_UTC (airports in Arizona like Phoenix to be cross-checked)\n",
    "* ARR_UTC (airports in Arizona like Phoenix to be cross-checked)<br>\n",
    "--> TRAVEL_DURATION_PLANNED to be re-calculated. Deviations to be analyzed.\n",
    "\n",
    "* WHEELS_OFF_TIME\n",
    "* WHEELS_ON_TIME<br>\n",
    "--> IN_AIR_DURATION to be re-calculated. Deviations to be analyzed.\n",
    "\n",
    "* TAXI_OUT_DURATION\n",
    "* TAXI_IN_DURATION<br>\n",
    "--> Together with the re-calculated IN_AIR_DURATION, the TRAVEL_DURATION is re-calculated. Deviations to be analyzed.\n",
    "--> Together with the re-calculated TRAVEL_DURATION, the ARR_TIME is re-calculated. Deviations to be analyzed.\n",
    "--> Together with the re-calculated ARR_TIME, the ARR_DELAY is re-calculated. Deviations to be analyzed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature, delivering negative values if arrival date is departure date + 1 day\n",
    "df['OVERMIDNIGHT'] = df['ARR_TIME_PLANNED'] - df['DEP_TIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overmidnighttobinary(x):\n",
    "    if x >= 0:\n",
    "        x = 0\n",
    "    elif x < 0:\n",
    "        x = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the values of OVERMIDNIGHT to 1 if arrival date is departure date + 1 day, otherwise to 0\n",
    "df['OVERMIDNIGHT'] = df['OVERMIDNIGHT'].apply(overmidnighttobinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of NaN values for each feature inside the flights dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting float to int format\n",
    "df['DISTANCE'] = df['DISTANCE'].astype('int64')\n",
    "df['DEP_TIME_PLANNED'] = df['DEP_TIME_PLANNED'].astype('str')\n",
    "df['ARR_TIME_PLANNED'] = df['ARR_TIME_PLANNED'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropadding(x):\n",
    "    if len(x) == 1:\n",
    "        x = '000' + x\n",
    "    elif len(x) == 2:\n",
    "        x = '00' + x\n",
    "    elif len(x) == 3:\n",
    "        x = '0' + x\n",
    "    if len(x) != 4:\n",
    "        print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_TIME_PLANNED'] = df['DEP_TIME_PLANNED'].apply(zeropadding)\n",
    "df['ARR_TIME_PLANNED'] = df['ARR_TIME_PLANNED'].apply(zeropadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloninseration(x):\n",
    "    x = str(x)\n",
    "    return x[:-2] + ':' + x[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DEP_TIME_PLANNED'] = df['DEP_TIME_PLANNED'].apply(coloninseration)\n",
    "df['ARR_TIME_PLANNED'] = df['ARR_TIME_PLANNED'].apply(coloninseration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DEP_DATETIME_PLANNED'] = df['FL_DATE'] + ' ' + df['DEP_TIME_PLANNED']\n",
    "df['ARR_DATETIME_PLANNED'] = df['FL_DATE'] + ' ' + df['ARR_TIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strtodatetime(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_DATETIME_PLANNED'] = df['DEP_DATETIME_PLANNED'].apply(strtodatetime)\n",
    "df['ARR_DATETIME_PLANNED'] = df['ARR_DATETIME_PLANNED'].apply(strtodatetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARR_DATETIME_PLANNED2'] = df[df['OVERMIDNIGHT'] == 1]['ARR_DATETIME_PLANNED'] + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ARR_DATETIME_PLANNED2'].isnull(),'ARR_DATETIME_PLANNED2'] = df['ARR_DATETIME_PLANNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ARR_DATETIME_PLANNED'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"ARR_DATETIME_PLANNED2\": \"ARR_DATETIME_PLANNED\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['OVERMIDNIGHT'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'C:\\Project_Data_NF/dfendofstep5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the number of missing values for 'ARR_DELAY' is higher than the number of missing values for 'ARR_TIME'. As 'ARR_TIME_PLANNED' does not have any missing values, the number of missing values for 'ARR_DELAY' can at least be reduced to the number of missing values for 'ARR_TIME' by calculating these values.\n",
    "\n",
    "ARR_DELAY = ARR_TIME - ARR_TIME_PLANNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Recovering ARR_DELAY data from ARR_TIME_PLANNED and ARR_TIME\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return int(int(x) % 100 + (int(x) - int(x) % 100) * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_TIME_PLANNED_COPY'] = df['DEP_TIME_PLANNED'].apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARR_TIME_PLANNED_COPY'] = df['ARR_TIME_PLANNED'].apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TRAVEL_DURATION_PLANNED'] = df['ARR_TIME_PLANNED_COPY'].subtract(df['DEP_TIME_PLANNED_COPY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    if x<0:\n",
    "        x = x + (24*60)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TRAVEL_DURATION_PLANNED2'] = df['TRAVEL_DURATION_PLANNED'].apply(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['TRAVEL_DURATION_PLANNED2'] <=5)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['ARR_DELAY'].isnull()) & (df['ARR_TIME'] < 300)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the percentage of NaN values for each feature inside the flights dataset\n",
    "df.isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN Values are okay for columns describing delay reasons as not all flights have delays. In this case these columns are empty.<br>\n",
    "Same for the cancellation code. Cancellations are rare, thus a high number of NaN values for cancellation reasons is okay.\n",
    "\n",
    "A detailed analysis for these columns is performed in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm = df[['DEP_DATETIME_PLANNED', 'ARR_DATETIME_PLANNED', 'AIRLINE_NAME', 'FL_DAYOFWEEK', 'DEP_AIRPORT', 'ARR_AIRPORT', 'DISTANCE', 'DEP_TIME', 'ARR_TIME', 'DEP_DELAY', 'TAXI_OUT_DURATION', 'WHEELS_OFF_TIME', 'WHEELS_ON_TIME', 'IN_AIR_DURATION', 'ARR_DELAY', 'DEP_LAT', 'DEP_LONG', 'DEP_ALT', 'DEP_TZ', 'ARR_LAT', 'ARR_LONG', 'ARR_ALT', 'ARR_TZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm_sample = df_pm.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_pm_sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIVERTED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the delay histogram\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.hist(df['ARR_DELAY'], bins=1000)\n",
    "plt.gca().set(title='Arrival Delay Histogram', ylabel='Count');\n",
    "plt.xlim(-50, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['DIVERTED'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['DIVERTED'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All flights of 2018\n",
    "df[(df['FL_DATE'] >= '2018-01-01') & (df['FL_DATE'] <= '2018-12-31')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'><b>bar</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ARR_TIME_PLANNED_COPY'] = df['ARR_TIME_PLANNED].apply(lambda x: int((int(x) % 100) + (int(x) - int(x) % 100) * 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the percentage of delayed flights per year\n",
    "plt.figure(figsize = (8,6))\n",
    "zaehler = df_delay[df_delay['ARR_DELAY'] == 1]['FL_YEAR'].value_counts()\n",
    "nenner = df_delay[df_delay['ARR_DELAY'] == 0]['FL_YEAR'].value_counts()\n",
    "cat = (zaehler/(zaehler+nenner)).sort_values(ascending=False)\n",
    "splot=sns.barplot(x=cat.index, y=cat.values, palette='RdYlGn_r')\n",
    "plt.ylim(0.0, 0.9)\n",
    "plt.title('Percentage of delayed flights per year', fontsize=16)\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1210\n",
    "print(int(x) % 100)\n",
    "print((int(x) - int(x) % 100) * 0.6)\n",
    "print(int(x) % 100 + (int(x) - int(x) % 100) * 0.6)\n",
    "print(int(str(x)[:-2]) * 60 + int(str(x)[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = '09/19/18 13:55:26'\n",
    "datetime_str2 = '2016-12-31 9:08'\n",
    "datetime_object = datetime.strptime(datetime_str, '%m/%d/%y %H:%M:%S')\n",
    "datetime_object2 = datetime.strptime(datetime_str2, '%Y-%m-%d %H:%M')\n",
    "datetime_object2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_small.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['DEP_TIME'] = df_small['DEP_TIME'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_small.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight delays (2016)\n",
    "print(len(df[(df['FL_DATE'] >= '2016-01-01') & (df['FL_DATE'] <= '2016-12-31') & (df['ARR_DELAY'] > 0)]))\n",
    "print(len(df[(df['FL_DATE'] >= '2016-01-01') & (df['FL_DATE'] <= '2016-12-31') & (df['ARR_DELAY'] > 0)]) / len(df[(df['FL_DATE'] >= '2016-01-01') & (df['FL_DATE'] <= '2016-12-31')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['DEP_TIME', 'ARR_TIME']].isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARR_DELAY'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARR_DELAY'].value_counts().sort_values(ascending=False).iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight delays (2017)\n",
    "print(len(df[(df['FL_DATE'] >= '2017-01-01') & (df['FL_DATE'] <= '2017-12-31') & (df['ARR_DELAY'] > 0)]))\n",
    "print(len(df[(df['FL_DATE'] >= '2017-01-01') & (df['FL_DATE'] <= '2017-12-31') & (df['ARR_DELAY'] > 0)]) / len(df[(df['FL_DATE'] >= '2017-01-01') & (df['FL_DATE'] <= '2017-12-31')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight delays (2018)\n",
    "print(len(df[(df['FL_DATE'] >= '2018-01-01') & (df['FL_DATE'] <= '2018-12-31') & (df['ARR_DELAY'] > 0)]))\n",
    "print(len(df[(df['FL_DATE'] >= '2018-01-01') & (df['FL_DATE'] <= '2018-12-31') & (df['ARR_DELAY'] > 0)]) / len(df[(df['FL_DATE'] >= '2018-01-01') & (df['FL_DATE'] <= '2018-12-31')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "labels = ['Not delayed', 'Delayed']\n",
    "sizes = df_delay[df_delay['FL_YEAR'] == '2016']['ARR_DELAY'].value_counts().values\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax1.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.title('Percentage of delayed flights in 2016', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
